{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/racoope70/BERTified/blob/main/Results_Rebalance_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XBnArpas7twX"
   },
   "outputs": [],
   "source": [
    "!pip -q install nbformat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 51989,
     "status": "ok",
     "timestamp": 1766453443811,
     "user": {
      "displayName": "Richard Cooper",
      "userId": "11337060935753111062"
     },
     "user_tz": 300
    },
    "id": "ZZh_Aj5CZS3k"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, get_scheduler\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from google.colab import drive\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "import gc  # Import garbage collection for memory management\n",
    "from huggingface_hub import notebook_login\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11839,
     "status": "ok",
     "timestamp": 1766453455654,
     "user": {
      "displayName": "Richard Cooper",
      "userId": "11337060935753111062"
     },
     "user_tz": 300
    },
    "id": "xUEvjRE05Yl4",
    "outputId": "b11429fc-188d-4e36-8b04-e20769436e2e"
   },
   "outputs": [],
   "source": [
    "# Dependencies (Colab only)\n",
    "!pip install transformers pandas scikit-learn imbalanced-learn torch torchvision torchaudio matplotlib seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1766453455660,
     "user": {
      "displayName": "Richard Cooper",
      "userId": "11337060935753111062"
     },
     "user_tz": 300
    },
    "id": "NPrtWJHL5lSZ"
   },
   "outputs": [],
   "source": [
    "# Load IMDb Dataset\n",
    "def load_imdb_dataset(base_path):\n",
    "    \"\"\"\n",
    "    Loads the IMDb dataset from given directory structure and returns a DataFrame with reviews and sentiments.\n",
    "    \"\"\"\n",
    "    reviews = []\n",
    "    sentiments = []\n",
    "\n",
    "    for split in ['train', 'test']:\n",
    "        for sentiment in ['pos', 'neg']:\n",
    "            path = os.path.join(base_path, split, sentiment)\n",
    "            for file_name in os.listdir(path):\n",
    "                with open(os.path.join(path, file_name), 'r', encoding='utf-8') as file:\n",
    "                    reviews.append(file.read())\n",
    "                    sentiments.append(1 if sentiment == 'pos' else 0)\n",
    "\n",
    "    return pd.DataFrame({'review': reviews, 'sentiment': sentiments})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 121195,
     "status": "ok",
     "timestamp": 1766453576860,
     "user": {
      "displayName": "Richard Cooper",
      "userId": "11337060935753111062"
     },
     "user_tz": 300
    },
    "id": "mlsfTrma5yWv",
    "outputId": "031074ca-c8de-43aa-c757-cb554d986616"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5000,
     "status": "ok",
     "timestamp": 1766453583568,
     "user": {
      "displayName": "Richard Cooper",
      "userId": "11337060935753111062"
     },
     "user_tz": 300
    },
    "id": "ABVPf2c450yy"
   },
   "outputs": [],
   "source": [
    "# Define paths for saving datasets and results\n",
    "base_path = '/content/drive/MyDrive/aclImdb'\n",
    "csv_file_path = '/content/drive/MyDrive/aclImdb_reviews.csv'\n",
    "results_dir = '/content/drive/MyDrive/sentiment_analysis_results'  # Define the directory for saving results\n",
    "\n",
    "# Ensure the results directory exists\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "if os.path.exists(csv_file_path):\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "else:\n",
    "    df = load_imdb_dataset(base_path)\n",
    "    df.to_csv(csv_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1766453583869,
     "user": {
      "displayName": "Richard Cooper",
      "userId": "11337060935753111062"
     },
     "user_tz": 300
    },
    "id": "z-QKxzd-6AF4"
   },
   "outputs": [],
   "source": [
    "# Fixed-size sample for faster iteration (reproducible)\n",
    "data = df.sample(10000, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 555,
     "status": "ok",
     "timestamp": 1766453586526,
     "user": {
      "displayName": "Richard Cooper",
      "userId": "11337060935753111062"
     },
     "user_tz": 300
    },
    "id": "vreqHUyu6DKk",
    "outputId": "02827d76-fe3b-4a86-aa09-5ea75fde6ef1"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    data['review'], data['sentiment'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Free up memory after splitting\n",
    "del df, data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9YHFMIdk6Tkm"
   },
   "outputs": [],
   "source": [
    "# Optional: Hugging Face authentication (only if rate-limited)\n",
    "# This allows for better access and avoids rate limits when downloading public models/datasets\n",
    "#notebook_login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "4ba0b0bc9236432aa223dbafaedd75d7",
      "60c13c9441194996bee9f7f6572d8b89",
      "93c6d0923248409c925275747d53f795",
      "7b7dc817fc624a3b8f6503c4dbcb1956",
      "559e5a945c274a12bce7a05b1a73033a",
      "0c5cab966e7a4c68ae3c1207036cbf87",
      "a67833d2e0c54c41933b898eb238fb0d",
      "3eb5204da7044258a9029033f6449d99",
      "7179c69107664348b9f72b82ffd760c4",
      "b638f077139949e48ceda1af94cc3791",
      "406e330b6c2b41e5a6de21acb3991ace",
      "32780c937f99429f9c531f899b0a6a19",
      "91d37ecfc9a84ebcb71f6a987e064007",
      "9f34e6a31ab6440891bf91ab150d9efb",
      "ab5279a92d034fe58593fda7a86027f8",
      "2ff01d58073a4d93857dd14240031e20",
      "bf453eae0f8f4572bddfd4e1247c1fc5",
      "40774f2af30748839c7f7b50a1748d72",
      "faec6bc8414a46d7a2b40ee61968b00d",
      "92536ea76c724f2cabc30fcd397fee70",
      "22df56bc0ffd4eab9b04563cd2640785",
      "4bab43e6b02f44e890045a501fb461d3",
      "22c940b5eafb4e0a899c15e7fdc715da",
      "200a0251455846e0aed7d34880717f5d",
      "b846e761c92642be98d77a9232d74fe3",
      "e707fbae37c942d4abef562d85b19e4c",
      "62cad5db23e04945baa707c3daf8f028",
      "00504a4cd5b54b87ba368ce24a694f5c",
      "40284633dade4778b0b5d89b577335ff",
      "34433ece27944328b8d9a035fc9c7e04",
      "bf246708afa548b29aadaf97735d7e2e",
      "9c877e1a42d34660b881fb9beeeea872",
      "b81789589fd84a8188f25e47d7b4731f",
      "627792f92bbb413fa4f5d8a7c9d9f44f",
      "14abf5409fdc4fe68e9377eca60ab0ab",
      "ef178df540ba43ee9ccbbd69972440c0",
      "a6a09b81b13549f981b48cc278cd6880",
      "be0bbe552e1f428586a9b13d4040dea9",
      "6ce2ef80e5604950b7c28c4e61fb99b9",
      "9cd63389c2074a2ba928c9c84a938175",
      "272636724a584dd88d1ba6fae69039ba",
      "6837861aac884e9883c533374b89960e",
      "e7f94da68b774a93a43742161af15c8c",
      "a3213f407e5642e989fa38a5dfd53fca"
     ]
    },
    "executionInfo": {
     "elapsed": 35972,
     "status": "ok",
     "timestamp": 1766453625029,
     "user": {
      "displayName": "Richard Cooper",
      "userId": "11337060935753111062"
     },
     "user_tz": 300
    },
    "id": "Krf9mq-M6XMq",
    "outputId": "67b2742f-1d34-4c5b-9f0e-69ef12849b93"
   },
   "outputs": [],
   "source": [
    "# Batch tokenization (memory-friendly)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_data(texts, tokenizer, batch_size=64):\n",
    "    \"\"\"\n",
    "    Tokenizes input texts in smaller batches to optimize memory usage.\n",
    "    \"\"\"\n",
    "    tokenized_data = {\"input_ids\": [], \"attention_mask\": []}\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i + batch_size].tolist()\n",
    "        encodings = tokenizer(batch, truncation=True, padding=True, max_length=256)\n",
    "        tokenized_data[\"input_ids\"].extend(encodings[\"input_ids\"])\n",
    "        tokenized_data[\"attention_mask\"].extend(encodings[\"attention_mask\"])\n",
    "    return tokenized_data\n",
    "\n",
    "train_encodings = tokenize_data(train_texts, tokenizer)\n",
    "test_encodings = tokenize_data(test_texts, tokenizer)\n",
    "\n",
    "train_texts_list = train_texts.tolist()\n",
    "train_labels_list = train_labels.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21316,
     "status": "ok",
     "timestamp": 1766453646347,
     "user": {
      "displayName": "Richard Cooper",
      "userId": "11337060935753111062"
     },
     "user_tz": 300
    },
    "id": "gKBc3XTvYcEC",
    "outputId": "6f30cb4f-37f2-4bde-b19e-d5dd3a93fe97"
   },
   "outputs": [],
   "source": [
    "# Dataset wrapper for Hugging Face Trainer\n",
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset class for sentiment analysis.\n",
    "    \"\"\"\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "train_texts_list = train_texts.tolist()  # Ensure train_texts is a list\n",
    "train_labels_list = train_labels.tolist()\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "train_texts_resampled, train_labels_resampled = ros.fit_resample(\n",
    "    pd.DataFrame({'text': train_texts_list}),  # Use a DataFrame to keep structure\n",
    "    train_labels_list\n",
    ")\n",
    "\n",
    "train_encodings_resampled = tokenizer(\n",
    "    train_texts_resampled['text'].tolist(), truncation=True, padding=True, max_length=128\n",
    ")\n",
    "\n",
    "train_dataset = SentimentDataset(train_encodings_resampled, list(train_labels_resampled))\n",
    "\n",
    "# Prepare testing dataset (unchanged)\n",
    "test_dataset = SentimentDataset(test_encodings, list(test_labels))\n",
    "\n",
    "# Free memory after creating datasets\n",
    "del train_encodings, test_encodings, train_labels, test_labels\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105,
     "referenced_widgets": [
      "d13a308f62744160a27c36eb18447eb7",
      "c313d8c900bd4f45bea87836e6983362",
      "e7c73a9c401848b8acc75bff60be92b1",
      "55397409b5564a26a80fe61bea077acf",
      "326f30ef149e4f878958a526994be3d0",
      "84bfa13266c5452d8fe24883d85dbb17",
      "85ad71b40d8e4979ad70c02cc3647796",
      "d7ceb72c3f664dc4a629a85859c40a06",
      "3c864588ea784c3d8f08072cd3d9d0b3",
      "b602bda62c3e49fb98f6413727e018da",
      "7b6885717a904d19a9460a6eb5b79357"
     ]
    },
    "executionInfo": {
     "elapsed": 10403,
     "status": "ok",
     "timestamp": 1766453656746,
     "user": {
      "displayName": "Richard Cooper",
      "userId": "11337060935753111062"
     },
     "user_tz": 300
    },
    "id": "pdsE-7C87tOk",
    "outputId": "30aa27ef-ff1e-4376-e108-a7c22203f96d"
   },
   "outputs": [],
   "source": [
    "# Initialize BERT sequence classifier (GPU-enabled if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 124,
     "status": "ok",
     "timestamp": 1766453656876,
     "user": {
      "displayName": "Richard Cooper",
      "userId": "11337060935753111062"
     },
     "user_tz": 300
    },
    "id": "Pe51FQW863_t"
   },
   "outputs": [],
   "source": [
    "# Training configuration (evaluation + checkpointing)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=results_dir,  # Save checkpoints to Google Drive\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=3,  # Limit the number of saved checkpoints\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.1,\n",
    "    logging_dir=os.path.join(results_dir, \"logs\"),  # Log directory\n",
    "    fp16=torch.cuda.is_available(),  # Mixed precision training\n",
    "    load_best_model_at_end=True,  # Load the best model\n",
    "    report_to=\"tensorboard\",\n",
    "    seed=42,\n",
    "    data_seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2187,
     "status": "ok",
     "timestamp": 1766453659072,
     "user": {
      "displayName": "Richard Cooper",
      "userId": "11337060935753111062"
     },
     "user_tz": 300
    },
    "id": "ScSJutf66_vv",
    "outputId": "013d5cfd-d9a8-4011-d9d9-b1e6a90500ed"
   },
   "outputs": [],
   "source": [
    "# Configure Trainer with checkpointing and evaluation\n",
    "# Optimizer and learning-rate schedule (accounts for gradient accumulation)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "steps_per_epoch = (len(train_dataset) // training_args.per_device_train_batch_size) + 1\n",
    "optimizer_steps_per_epoch = max(1, steps_per_epoch // training_args.gradient_accumulation_steps)\n",
    "num_training_steps = int(optimizer_steps_per_epoch * training_args.num_train_epochs)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 869,
     "status": "ok",
     "timestamp": 1766453659946,
     "user": {
      "displayName": "Richard Cooper",
      "userId": "11337060935753111062"
     },
     "user_tz": 300
    },
    "id": "QdzG9dwyqlJi"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    optimizers=(optimizer, lr_scheduler),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "executionInfo": {
     "elapsed": 430309,
     "status": "ok",
     "timestamp": 1766454091310,
     "user": {
      "displayName": "Richard Cooper",
      "userId": "11337060935753111062"
     },
     "user_tz": 300
    },
    "id": "qh6s_W_y7gcz",
    "outputId": "eb94b99b-a30c-46cc-d81a-f909ec960235"
   },
   "outputs": [],
   "source": [
    "# Begin fine-tuning\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 6524,
     "status": "ok",
     "timestamp": 1766454097828,
     "user": {
      "displayName": "Richard Cooper",
      "userId": "11337060935753111062"
     },
     "user_tz": 300
    },
    "id": "5DyKP-zF8CKs",
    "outputId": "af070f1e-70db-4894-c579-9f688b04c418"
   },
   "outputs": [],
   "source": [
    "# Evaluate model on held-out test set\n",
    "preds = trainer.predict(test_dataset).predictions\n",
    "\n",
    "test_labels_tensor = torch.tensor(list(test_dataset.labels)).to(torch.device(\"cpu\"))\n",
    "binary_preds = torch.argmax(torch.tensor(preds), dim=1)\n",
    "accuracy = accuracy_score(test_labels_tensor.numpy(), binary_preds.numpy())\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 6757,
     "status": "ok",
     "timestamp": 1766454104586,
     "user": {
      "displayName": "Richard Cooper",
      "userId": "11337060935753111062"
     },
     "user_tz": 300
    },
    "id": "WxvO0l2B1dHo",
    "outputId": "f9463f45-38af-4c04-a7e6-d89904c7d405"
   },
   "outputs": [],
   "source": [
    "# Obtain predictions and true labels\n",
    "output = trainer.predict(test_dataset)  # Get predictions and metrics from the model\n",
    "predictions = output.predictions  # Raw predictions from the model\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_labels = torch.argmax(torch.tensor(predictions), dim=1).numpy()\n",
    "\n",
    "# Extract true labels from the test dataset\n",
    "true_labels = [example['labels'] for example in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 189,
     "status": "ok",
     "timestamp": 1766454104777,
     "user": {
      "displayName": "Richard Cooper",
      "userId": "11337060935753111062"
     },
     "user_tz": 300
    },
    "id": "bej-WBP0wCOF",
    "outputId": "6bd35563-ff79-422d-c8ba-4b3b17afe78b"
   },
   "outputs": [],
   "source": [
    "# Summary metrics on held-out test set\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average=\"binary\")\n",
    "recall = recall_score(true_labels, predicted_labels, average=\"binary\")\n",
    "f1 = f1_score(true_labels, predicted_labels, average=\"binary\")\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n",
    "\n",
    "# Detailed per-class breakdown\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 700,
     "status": "ok",
     "timestamp": 1766454105479,
     "user": {
      "displayName": "Richard Cooper",
      "userId": "11337060935753111062"
     },
     "user_tz": 300
    },
    "id": "egRUrGxRPe0a",
    "outputId": "8b0d956f-98a5-40f9-977a-12b759b438fc"
   },
   "outputs": [],
   "source": [
    "# Threshold-based diagnostics (ROC, PR, confusion matrix)\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, roc_curve, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert logits to positive-class probabilities for threshold-based diagnostics\n",
    "probs = torch.softmax(torch.tensor(predictions), dim=1).numpy()\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "disp.plot()\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display ROC-AUC score\n",
    "roc_auc = roc_auc_score(true_labels, probs[:, 1])\n",
    "print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# ROC-AUC and ROC curve\n",
    "fpr, tpr, _ = roc_curve(true_labels, probs[:, 1])\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Precisionâ€“Recall curve (positive class)\n",
    "precision, recall, _ = precision_recall_curve(true_labels, probs[:, 1])\n",
    "plt.plot(recall, precision, label=\"Precision-Recall Curve\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
